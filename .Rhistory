p <- logit_p(x, beta0, beta1)
y[is.na(y)] <- ifelse(p[is.na(y)] > 0.5, 1, 0)
# M-step: Update beta by maximizing the log likelihood
result <- optim(c(beta0, beta1), fn = function(beta)-log_likelihood(beta))
beta_new <- result$par
# Check for convergence
if (sqrt(sum((beta_new - c(beta0, beta1))^2)) < tol) {
cat("Converged in", iter, "iterations\n")
return(list(beta0 = beta_new[1], beta1 = beta_new[2]))
}
beta0 <- beta_new[1]
beta1 <- beta_new[2]
}
cat("Max iterations reached without convergence\n")
return(list(beta0 = beta0, beta1 = beta1))
}
# Run the EM algorithm
result <- em_algorithm(x, y)
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")  # Load the data
#require(maxLik)
EM_Bernoulli <- function(data, beta0, eps){
x <- dataex5[,1]
y <- dataex5[,2]
n <- length(y)
data1 <- na.omit(dataex5)
y1 <- data1[,2]
data2 <- dataex5[which(!complete.cases(dataex5)),]
y2 <- data2[,2]
m1 <- length(y1)
m2 <- length(y2)
beta <- beta0
diff <- 1
while (diff > eps) {
beta_old <- beta
#E_step
E_step <- function(beta, beta_old, data1, data2){
x1 <- data1[,1]
y1 <- data1[,2]
x2 <- data2[,1]
y2 <- data2[,2]
pi1 <- exp(beta[1] + x1 * beta[2])/(1+exp(beta[1] + x1 * beta[2]))
pi2_new <- exp(beta[1] + x2 * beta[2])/(1+exp(beta[1] + x2 * beta[2]))
pi2_old <- exp(beta_old[1] + x2 * beta_old[2])/(1+exp(beta_old[1] + x2 * beta_old[2]))
result <- sum(y1 * log(pi1) + (1 - y1) * log(1 -  pi1))+sum(pi2_old * log(pi2_new) + (1 - pi2_old) * log(1 - pi2_new))
return(-result)
}
#M_step
MLE <- optim(par = beta, E_step, data1 = data1, data2 = data2,  beta_old = beta_old)
beta <- MLE$par
diff <- sum(abs(beta - beta_old))
}
return(beta)
}
beta0 <- c(0,0)
EM_Bernoulli(data = dataex5, beta0 = beta0, eps = 0.00000001)
x <- dataex5[,1]; y <- dataex5[,2]
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
x <- dataex5[,1]  # Predictor
y <- dataex5[,2]  # Response with NAs
n <- length(y)
# 分离有响应值和缺失响应值的数据
data1 <- na.omit(dataex5)
y1 <- data1[,2]
x1 <- data1[,1]
data2 <- dataex5[is.na(dataex5[,2]), ]
x2 <- data2[,1]
# 初始化参数
beta <- c(0, 0)
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta_old <- beta
# E-step: 对缺失数据的期望值进行更新
pi1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
pi2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
# M-step: 通过最大化似然函数来更新参数
logLikelihood <- function(beta) {
pi1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
pi2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
ll <- sum(y1 * log(pi1) + (1 - y1) * log(1 - pi1)) + sum(log(pi2))
return(-ll)
}
MLE <- optim(par = beta, fn = logLikelihood, method = "BFGS")
beta <- MLE$par
# 检查收敛
diff <- sum(abs(beta - beta_old))
}
print(beta)
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
x <- dataex5[,1]  # Predictor
y <- dataex5[,2]  # Response with NAs
n <- length(y)
# 分离有响应值和缺失响应值的数据
data1 <- na.omit(dataex5)
y1 <- data1[,2]
x1 <- data1[,1]
data2 <- dataex5[which(!complete.cases(dataex5)),]
x2 <- data2[,1]
# 初始化参数
beta <- c(0, 0)
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta_old <- beta
# E-step: 对缺失数据的期望值进行更新
pi1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
pi2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
# M-step: 通过最大化似然函数来更新参数
logLikelihood <- function(beta) {
pi1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
pi2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
ll <- sum(y1 * log(pi1) + (1 - y1) * log(1 - pi1)) + sum(log(pi2))
return(-ll)
}
MLE <- optim(par = beta, fn = logLikelihood, method = "BFGS")
beta <- MLE$par
# 检查收敛
diff <- sum(abs(beta - beta_old))
}
print(beta)
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
x <- dataex5[,1]  # Predictor
y <- dataex5[,2]  # Response with NAs
n <- length(y)
# 分离有响应值和缺失响应值的数据
data1 <- na.omit(dataex5)
y1 <- data1[,2]
x1 <- data1[,1]
data2 <- dataex5[which(!complete.cases(dataex5)),]
x2 <- data2[,1]
# 初始化参数
beta <- c(0, 0)
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta_old <- beta
# E-step: 对缺失数据的期望值进行更新
pi1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
pi2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
# M-step: 通过最大化似然函数来更新参数
logLikelihood <- function(beta) {
pi1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
pi2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
return(-(sum(y1 * log(pi1) + (1 - y1) * log(1 - pi1)) + sum(log(pi2))))
}
MLE <- optim(par = beta, fn = logLikelihood)
beta <- MLE$par
# 检查收敛
diff <- sum(abs(beta - beta_old))
}
print(beta)
dataex5[which(!complete.cases(dataex5)),]
dataex5[is.na(dataex5[,2]), ]
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
x <- dataex5[,1]
y <- dataex5[,2]
data1 <- na.omit(dataex5)
x1 <- data1[,1]
y1 <- data1[,2]
data2 <- dataex5[is.na(dataex5[,2]), ]
x2 <- data2[,1]
y2 <- data2[,2]
beta0 <- c(0, 0)
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta <- beta0
p_i1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
p_i2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
p_i0 <- exp(beta0[1] + x2 * beta0[2]) / (1 + exp(beta0[1] + x2 * beta0[2]))
result <- sum(y1*log(p_i1)+(1-y1)*log(1-p_i1))+sum(p_i0*log(p_i2)+(1-p_i0)*log(1-p_i2))
MLE <- optim(par = beta, fn = -result)
beta <- MLE$par
diff <- sum(abs(beta - beta0))
}
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
x <- dataex5[,1]
y <- dataex5[,2]
data1 <- na.omit(dataex5)
x1 <- data1[,1]
y1 <- data1[,2]
data2 <- dataex5[is.na(dataex5[,2]), ]
x2 <- data2[,1]
y2 <- data2[,2]
beta0 <- c(0, 0)
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta <- beta0
p_i1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
p_i2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
p_i0 <- exp(beta0[1] + x2 * beta0[2]) / (1 + exp(beta0[1] + x2 * beta0[2]))
result <- sum(y1*log(p_i1)+(1-y1)*log(1-p_i1))+sum(p_i0*log(p_i2)+(1-p_i0)*log(1-p_i2))
MLE <- optim(par = beta, -result)
beta <- MLE$par
diff <- sum(abs(beta - beta0))
}
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
x <- dataex5[,1]
y <- dataex5[,2]
data1 <- na.omit(dataex5)
x1 <- data1[,1]
y1 <- data1[,2]
data2 <- dataex5[is.na(dataex5[,2]), ]
x2 <- data2[,1]
y2 <- data2[,2]
beta0 <- c(0, 0)
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta <- beta0
logLikelihood <- function(beta) {
p_i1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
p_i2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
p_i0 <- exp(beta0[1] + x2 * beta0[2]) / (1 + exp(beta0[1] + x2 * beta0[2]))
result <- sum(y1*log(p_i1)+(1-y1)*log(1-p_i1))+sum(p_i0*log(p_i2)+(1-p_i0)*log(1-p_i2))
return(-result)
}
MLE <- optim(par = beta, fn = logLikelihood)
beta <- MLE$par
diff <- sum(abs(beta - beta0))
}
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
x <- dataex5[,1]
y <- dataex5[,2]
data1 <- na.omit(dataex5)
x1 <- data1[,1]
y1 <- data1[,2]
data2 <- dataex5[is.na(dataex5[,2]), ]
x2 <- data2[,1]
y2 <- data2[,2]
beta0 <- c(0, 0)
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta <- beta0
p_i1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
p_i2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
logLikelihood <- function(beta) {
p_i1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
p_i2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
p_i0 <- exp(beta0[1] + x2 * beta0[2]) / (1 + exp(beta0[1] + x2 * beta0[2]))
result <- sum(y1*log(p_i1)+(1-y1)*log(1-p_i1))+sum(p_i0*log(p_i2)+(1-p_i0)*log(1-p_i2))
return(-result)
}
MLE <- optim(par = beta, fn = logLikelihood)
beta <- MLE$par
diff <- sum(abs(beta - beta0))
}
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
x <- dataex5[,1]
y <- dataex5[,2]
data1 <- na.omit(dataex5)
x1 <- data1[,1]
y1 <- data1[,2]
data2 <- dataex5[is.na(dataex5[,2]), ]
x2 <- data2[,1]
y2 <- data2[,2]
beta0 <- c(0, 0)
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta <- beta0
p_i1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
p_i2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
logLikelihood <- function(beta) {
p_i1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
p_i2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
result <- sum(y1*log(p_i1)+(1-y1)*log(1-p_i1)) + sum(log(p_i2))  # 对于缺失数据，可能需要调整
return(-result)
}
MLE <- optim(par = beta, fn = logLikelihood, method = "BFGS")
beta <- MLE$par
# 检查收敛
diff <- sum(abs(beta - beta_old))
beta_old <- beta  # 更新上一次迭代的beta值
}
print(beta)
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
x <- dataex5[,1]
y <- dataex5[,2]
data1 <- na.omit(dataex5)
x1 <- data1[,1]
y1 <- data1[,2]
data2 <- dataex5[is.na(dataex5[,2]), ]
x2 <- data2[,1]
y2 <- data2[,2]
beta0 <- c(0, 0)
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta_old <- beta0
p_i1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
p_i2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
logLikelihood <- function(beta) {
pi1 <- exp(beta[1] + x1 * beta[2])/(1+exp(beta[1] + x1 * beta[2]))
pi2_new <- exp(beta[1] + x2 * beta[2])/(1+exp(beta[1] + x2 * beta[2]))
pi2_old <- exp(beta_old[1] + x2 * beta_old[2])/(1+exp(beta_old[1] + x2 * beta_old[2]))
result <- sum(y1 * log(pi1) + (1 - y1) * log(1 -  pi1))+sum(pi2_old * log(pi2_new) + (1 - pi2_old) * log(1 - pi2_new))
return(-result)
}
MLE <- optim(par = beta, fn = logLikelihood)
beta <- MLE$par
diff <- sum(abs(beta - beta0))
}
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
x <- dataex5[,1]
y <- dataex5[,2]
data1 <- na.omit(dataex5)
x1 <- data1[,1]
y1 <- data1[,2]
data2 <- dataex5[is.na(dataex5[,2]), ]
x2 <- data2[,1]
y2 <- data2[,2]
beta0 <- c(0, 0)
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta_old <- beta0
p_i1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
p_i2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
logLikelihood <- function(beta, beta_old) {
pi1 <- exp(beta[1] + x1 * beta[2])/(1+exp(beta[1] + x1 * beta[2]))
pi2_new <- exp(beta[1] + x2 * beta[2])/(1+exp(beta[1] + x2 * beta[2]))
pi2_old <- exp(beta_old[1] + x2 * beta_old[2])/(1+exp(beta_old[1] + x2 * beta_old[2]))
result <- sum(y1 * log(pi1) + (1 - y1) * log(1 -  pi1))+sum(pi2_old * log(pi2_new) + (1 - pi2_old) * log(1 - pi2_new))
return(-result)
}
MLE <- optim(par = beta, fn = logLikelihood, beta_old=beta0)
beta <- MLE$par
diff <- sum(abs(beta - beta0))
}
beta <- beta0
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
data1 <- na.omit(dataex5)
x1 <- data1[,1]
y1 <- data1[,2]
data2 <- dataex5[is.na(dataex5[,2]), ]
x2 <- data2[,1]
y2 <- data2[,2]
beta0 <- c(0, 0)
beta <- beta0
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta_old <- beta
pi1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
pi2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
logLikelihood <- function(beta, beta_old) {
pi1 <- exp(beta[1] + x1 * beta[2])/(1+exp(beta[1] + x1 * beta[2]))
pi2_new <- exp(beta[1] + x2 * beta[2])/(1+exp(beta[1] + x2 * beta[2]))
pi2_old <- exp(beta_old[1] + x2 * beta_old[2])/(1+exp(beta_old[1] + x2 * beta_old[2]))
result <- sum(y1 * log(pi1) + (1 - y1) * log(1 -  pi1))+sum(pi2_old * log(pi2_new) + (1 - pi2_old) * log(1 - pi2_new))
return(-result)
}
MLE <- optim(par = beta, fn = logLikelihood, beta_old=beta0)
beta <- MLE$par
diff <- sum(abs(beta - beta0))
}
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
data1 <- na.omit(dataex5)
x1 <- data1[,1]
y1 <- data1[,2]
data2 <- dataex5[is.na(dataex5[,2]), ]
x2 <- data2[,1]
y2 <- data2[,2]
beta0 <- c(0, 0)
beta <- beta0
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta_old <- beta
# pi1 <- exp(beta[1] + x1 * beta[2]) / (1 + exp(beta[1] + x1 * beta[2]))
# pi2 <- exp(beta[1] + x2 * beta[2]) / (1 + exp(beta[1] + x2 * beta[2]))
logLikelihood <- function(beta, beta_old) {
pi1 <- exp(beta[1] + x1 * beta[2])/(1+exp(beta[1] + x1 * beta[2]))
pi2_new <- exp(beta[1] + x2 * beta[2])/(1+exp(beta[1] + x2 * beta[2]))
pi2_old <- exp(beta_old[1] + x2 * beta_old[2])/(1+exp(beta_old[1] + x2 * beta_old[2]))
result <- sum(y1 * log(pi1) + (1 - y1) * log(1 -  pi1))+sum(pi2_old * log(pi2_new) + (1 - pi2_old) * log(1 - pi2_new))
return(-result)
}
MLE <- optim(par = beta, fn = logLikelihood, beta_old=beta_old)
beta <- MLE$par
diff <- sum(abs(beta - beta_old))
}
print(beta)
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
data1 <- na.omit(dataex5)
x1 <- data1[,1]
y1 <- data1[,2]
data2 <- dataex5[is.na(dataex5[,2]), ]
x2 <- data2[,1]
y2 <- data2[,2]
beta0 <- c(0, 0)
# beta <- beta0
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta_old <- beta0
logLikelihood <- function(beta, beta_old) {
pi1 <- exp(beta[1] + x1 * beta[2])/(1+exp(beta[1] + x1 * beta[2]))
pi2_new <- exp(beta[1] + x2 * beta[2])/(1+exp(beta[1] + x2 * beta[2]))
pi2_old <- exp(beta_old[1] + x2 * beta_old[2])/(1+exp(beta_old[1] + x2 * beta_old[2]))
result <- sum(y1 * log(pi1) + (1 - y1) * log(1 -  pi1))+sum(pi2_old * log(pi2_new) + (1 - pi2_old) * log(1 - pi2_new))
return(-result)
}
MLE <- optim(par = beta, fn = logLikelihood, beta_old=beta_old)
beta <- MLE$par
diff <- sum(abs(beta - beta_old))
}
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
data1 <- na.omit(dataex5)
x1 <- data1[,1]
y1 <- data1[,2]
data2 <- dataex5[is.na(dataex5[,2]), ]
x2 <- data2[,1]
y2 <- data2[,2]
beta0 <- c(0, 0)
beta <- beta0
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta_old <- beta
logLikelihood <- function(beta, beta_old) {
pi1 <- exp(beta[1] + x1 * beta[2])/(1+exp(beta[1] + x1 * beta[2]))
pi2_new <- exp(beta[1] + x2 * beta[2])/(1+exp(beta[1] + x2 * beta[2]))
pi2_old <- exp(beta_old[1] + x2 * beta_old[2])/(1+exp(beta_old[1] + x2 * beta_old[2]))
result <- sum(y1 * log(pi1) + (1 - y1) * log(1 -  pi1))+sum(pi2_old * log(pi2_new) + (1 - pi2_old) * log(1 - pi2_new))
return(-result)
}
MLE <- optim(par = beta, fn = logLikelihood, beta_old=beta_old)
beta <- MLE$par
diff <- sum(abs(beta - beta_old))
}
print(beta)
# Question 4
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
load("dataex5.Rdata")
#require(maxLik)
data1 <- na.omit(dataex5)
x1 <- data1[,1]
y1 <- data1[,2]
data2 <- dataex5[is.na(dataex5[,2]), ]
x2 <- data2[,1]
y2 <- data2[,2]
beta0 <- c(0, 0)
beta <- beta0
eps <- 1e-8
diff <- 1
while (diff > eps) {
beta_old <- beta
logLikelihood <- function(beta, beta_old) {
pi1 <- exp(beta[1] + x1 * beta[2])/(1+exp(beta[1] + x1 * beta[2]))
pi2 <- exp(beta[1] + x2 * beta[2])/(1+exp(beta[1] + x2 * beta[2]))
pi2_old <- exp(beta_old[1] + x2 * beta_old[2])/(1+exp(beta_old[1] + x2 * beta_old[2]))
result <- sum(y1*log(pi1)+(1-y1)*log(1-pi1))+sum(pi2_old*log(pi2)+(1-pi2_old)*log(1-pi2))
return(-result)
}
MLE <- optim(par = beta, fn = logLikelihood, beta_old=beta_old)
beta <- MLE$par
diff <- sum(abs(beta - beta_old))
}
print(beta)
# Question 5
setwd("C:/Users/lenovo/Desktop/IDA_Assignment1")
420/2000
(200+220+160)/3000
280/2000
